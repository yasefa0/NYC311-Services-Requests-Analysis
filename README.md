# NYC311 Business Intelligence Project

This project analyzes NYC 311 Service Request data using AWS tools to build a scalable Business Intelligence (BI) pipeline and dashboard environment.
---

## ğŸš€ Project Goals

- Extract 2025 NYC311 data using the Socrata Open Data API (SODA)
- Stage raw data in AWS S3 in partitioned format
- Load data into Amazon Redshift using a star schema
- Build interactive dashboards using Amazon QuickSight

---

## ğŸ—ï¸ Architecture

![Project Architecture](docs/architecture.png)

This architecture shows how raw NYC311 data flows from ingestion to visualization

---

## ğŸ“… Data Source

- **Source**: [NYC Open Data â€“ 311 Service Requests (2010â€“Present)](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9)
- **Date Range Pulled**: January 1, 2025 â€“ June 30, 2025
- **Total Rows**: ~1.73 million
- **Columns**: 16 selected for BI (timestamp, agency, complaint, geo, resolution)

---

## ğŸ“¦ S3 Data Storage

Raw files have been uploaded to:

s3://nyc311-bi-project-data/raw/311_service_requests/year=2025/


**Contents:**
- `nyc311_2025H1_all.csv` â€“ Combined full dataset (~700MB)
- `nyc311_2025H1_*.csv` â€“ Individual batch files for scalable ETL

> âš ï¸ These CSVs are not committed to Git and are excluded using `.gitignore`.

---

## ğŸ§° Tech Stack

- **ETL**: Python, AWS Glue (planned), Socrata API
- **Storage**: Amazon S3
- **Data Modeling**: Star schema design (fact + dimension)
- **Warehouse**: Amazon Redshift
- **Dashboards**: Amazon QuickSight
- **Languages**: Python, SQL (Redshift), Jupyter
- **Version Control**: Git + GitHub

---

## ğŸ“Š Data Warehouse Design

- Loaded `raw_311` into Redshift via S3 using `COPY`
- Created star schema: `dim_date`, `dim_location`, `dim_complaint_type`, `fact_service_request`
- Cleaned duplicates using `vw_raw_311_deduped` view
- Fact table tracks resolution time, location, complaint type, and status

---

### ğŸ§¼ Data Integrity
- Total rows in `raw_311`: 1,733,709
- Successfully modeled into fact table: 1,616,767 (~93.3%)
- Dropped due to:
  - Location mismatch: 84,995
  - Complaint mismatch: 39,416
  - âœ… **Pct. loaded into analytics layer**: **93.25%**

---

## âœ… Current Progress

- âœ… Extracted and cleaned 1.7M NYC311 records (2025 H1)
- âœ… Uploaded to S3 (raw zone) in both batch and full formats
- âœ… Implemented full star schema in Redshift:
  - `dim_date`, `dim_location`, `dim_complaint_type`, `fact_service_request`
  - Deduplicated source via `vw_raw_311_deduped`
- âœ… SQL scripts added to `scripts/sql/redshift/`
- âœ… Created [KPI views](scripts/sql/redshift/create_kpi_views.sql) in Redshift
- âœ… Connected Redshift to QuickSight and published SPICE dataset

---

## ğŸ“Š Amazon QuickSight Dashboard

#### Executive Summary  
![KPI Summary](dashboards/Quicksight/Slice1.png)

#### Complaint Patterns & Trends  
![Trends & Heatmap](dashboards/Quicksight/Slice2.png)

#### NYC Complaint Density Map  
![Geospatial Map](dashboards/Quicksight/Slice3.png)

**Key Features:**
- Total requests, resolution time, and open request % shown as KPI cards
- Monthly trends and complaint breakdowns by borough
- Heatmap of complaint types Ã— boroughs
- Interactive NYC geospatial map of complaint clusters

---
## ğŸ“Œ Next Steps

- [ ] Add AWS Glue job for incremental data refresh
- [ ] Enhance dashboard with filters and controls (e.g., borough selector)
- [ ] Publish final walkthrough summary and demo link

---

## ğŸ“ Repo Structure

nyc311-bi-project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                     # Local CSVs (ignored in Git)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ glue_jobs/              # ETL logic (Python)
â”‚   â””â”€â”€ sql/
â”‚       â””â”€â”€ redshift/           # DDL, COPY, KPIs
â”œâ”€â”€ notebooks/                  # Optional: EDA or prototypes
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ quicksight/             # QuickSight screenshots (sliced PNGs)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ schema_diagram.png
â”‚   â””â”€â”€ architecture.png
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt

---

Built to showcase practical BI engineering skills using modern AWS and SQL tooling.